# -*- coding: utf-8 -*-
"""hackethernet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bqGFU0F1QxVmqS-ADXrl7k3KyycKN7CI
"""

import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np
import random

from google.colab import drive

drive.mount("/content/drive")

"""**LOad Dataset**"""

# os.mkdir("/content/dataset2")
# !unrar x "/content/drive/MyDrive/Dataset.rar" "/content/dataset2"

import zipfile
zip_ref = zipfile.ZipFile("/content/drive/MyDrive/attentive_ness.zip", 'r')
zip_ref.extractall("/content/dataset2")
zip_ref.close()

import numpy as np
import cv2
from tensorflow.keras.utils import Sequence
import tensorflow as tf
import os
import json


class DataGenerator(Sequence):
    def __init__(self, x_data, y_data,
                 batch_size=32, dim=(320,240),
                 shuffle=True):
        self.x_data = x_data
        self.y_data = y_data
        self.batch_size = batch_size
        self.dim = dim


    def __len__(self):
        return int(np.floor(len(self.x_data) / self.batch_size))


    def __getitem__(self, index):
        start_index = index * self.batch_size
        x_train = []
        y_train_depth = []
        # y_train_semantic = []
        i = start_index
        while len(x_train) < self.batch_size:
            try:
                
                img = cv2.imread(self.x_data[i % len(self.x_data)])
                img = cv2.resize(img,(224,224))
                # print(img.shape)
                # img = np.array(img, dtype = np.float32)
                img = img / 255.0

               
                y = np.zeros((3,))
                y[self.y_data[i%len(self.y_data)]]=1
                x_train.append(img)
                y_train_depth.append(y)



                i += 1

            except Exception as err:
                print(err)
                continue
      
            
        # x_train = np.array(x_train)
        # y_train_depth = np.array(y_train_depth)
        # y_train_semantic = np.array(y_train_semantic)
            
  
        return np.array(x_train),np.array(y_train_depth)

import numpy as np
import cv2
from tensorflow.keras.utils import Sequence
import tensorflow as tf
import os
import json


class Second_DataGenerator(Sequence):
    def __init__(self, x_data, y_data,
                 batch_size=32, dim=(320,240),
                 shuffle=True):
        self.x_data = x_data
        self.y_data = y_data
        # self.y_semantic = y_semantic
        self.batch_size = batch_size
        self.dim = dim


    def __len__(self):
        return int(np.floor(len(self.x_data) / self.batch_size))


    def __getitem__(self, index):
        start_index = index * self.batch_size
        x_train = []
        y_train_depth = []
        # y_train_semantic = []
        i = start_index
        while len(x_train) < self.batch_size:
            try:
                
                img = cv2.imread(self.x_data[i % len(self.x_data)])
                img = cv2.resize(img,(224,224))
                # print(img.shape)
                # img = np.array(img, dtype = np.float32)
                img = img / 255.0

               
                y = np.zeros((3,))
                y[self.y_data[i%len(self.y_data)]]=1
                x_train.append(img)
                y_train_depth.append(y)



                i += 1

            except Exception as err:
                print(err)
                continue
      
            
        # x_train = np.array(x_train)
        # y_train_depth = np.array(y_train_depth)
        # y_train_semantic = np.array(y_train_semantic)
            
  
        return np.array(x_train),np.array(y_train_depth)

outputs  = {"looking_sideways":0 , "looking_straight":1, "yawing":2}
path = "/content/dataset2/attentive_ness"
x_data = []
y_data = []
for folder in os.listdir(path):
    for img in os.listdir(os.path.join(path, folder)):
        img_path = os.path.join(path, os.path.join(folder,img))
        x_data.append(img_path)
        y_data.append(outputs[folder])
# path = "/content/dataset2/New Dataset"
# for folder in os.listdir(path):
#     for img in os.listdir(os.path.join(path, folder)):
#         img_path = os.path.join(path, os.path.join(folder,img))
#         x_data.append(img_path)
#         y_data.append(outputs[folder])      
# outputs  = {"A":0, "B":1, "C":2, "D": 3, "E":4, "F":5, "G": 6, "H":7, "I":8, "J":9, "K":10, "L":11, "M":12, "N":13, "O":14, "P":15, "Q":16, "R":17, "S":18, "T":19, "U":20, "V":21, "W":22, "X":23, "Y":24, "Z": 25, "Space bar": 26}
# path = "/content/dataset2/dataset"
# for folder in os.listdir(path):
#     for img in os.listdir(os.path.join(path, folder)):
#         img_path = os.path.join(path, os.path.join(folder,img))
#         x_data.append(img_path)
#         y_data.append(outputs[folder])

x_data = np.array(x_data)
y_data = np.array(y_data)
temp = list(zip(x_data, y_data))
random.shuffle(temp)
x_data, y_data= zip(*temp)

temp = list(zip(x_data, y_data))
random.shuffle(temp)
x_data, y_data= zip(*temp)

train_data = DataGenerator(x_data[:int(len(x_data)*0.95)], y_data[:int(len(x_data)*0.95)], batch_size=4)

val_data = Second_DataGenerator(x_data[int(len(x_data)*0.95):], y_data[int(len(x_data)*0.95):], batch_size=4)

#



# x_test = x_train[int(x_train.shape[0]*0.8):]
# y_test = y_out[int(y_train.shape[0]*0.8):]
# x_train = x_train[:int(x_train.shape[0]*0.8)]
# y_train =  y_out[:int(y_train.shape[0]*0.8)]



# model = Sequential()
# mdoel.add(Conv2D())

from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, InputLayer, BatchNormalization, Dense, Dropout
from tensorflow import lite
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import categorical_crossentropy
model_resnet=tf.keras.applications.MobileNetV2(
    include_top=False, weights='imagenet', input_tensor=None,
    input_shape=(224, 224, 3), pooling=None, 
)
flat = tf.keras.layers.GlobalAveragePooling2D()(model_resnet.layers[-1].output)
d1 = Dense(units=512, activation='relu')(flat)
d1 = Dense(units=126, activation='relu')(d1)
d2 = Dense(units=3, activation='softmax')(d1)
from tensorflow.keras import Model    
model=Model(inputs=model_resnet.inputs,outputs=d2)
# model.summary()
from tensorflow.keras.optimizers import Adam
optimizer=Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

history = model.fit(train_data, epochs =  5, validation_data= val_data)

model.save_weights('/content/drive/MyDrive/hackethernet.h5')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model.
with open('/content/drive/MyDrive/model.tflite', 'wb') as f:
  f.write(tflite_model)

from tensorflow import lite

model.evaluate(train_data)

img = cv2.imread("/content/WhatsApp Image 2021-05-15 at 10.41.45 PM.jpeg")
img = cv2.resize(img, (224,224))
img = img/255.0
plt.imshow(img)
img = np.expand_dims(img, axis=0)
output = model.predict(img)
print(np.argmax(output, axis =1))

voutput = model.predict(img)

print(np.argmax(output, axis =1))

